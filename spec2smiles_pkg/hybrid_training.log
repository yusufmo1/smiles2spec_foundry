============================================================
TRAINING HYBRID CNN-TRANSFORMER: Spectrum -> Descriptors
============================================================
Loading data from ../spec2smiles/data/processed/hpj...
  Train: 2176 samples
  Val: 272 samples
  Spectrum bins: 500
  Descriptors: 12

Hybrid CNN-Transformer configuration:
  cnn_hidden: 512
  transformer_dim: 512
  n_heads: 8
  n_layers: 6
  d_ff: 2048
  dropout: 0.1
  learning_rate: 0.0003
  batch_size: 64
  max_epochs: 300
  patience: 50
  device: cuda
/home/yusuf/smiles2spec_foundry/spec2smiles_pkg/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True
  warnings.warn(
HybridCNNTransformer initialized with 32,410,630 parameters
  - CNN hidden: 512
  - Transformer dim: 512
  - Heads: 8
  - Transformer layers: 6
  - Device: cuda

Training for up to 300 epochs...
  - Train samples: 2176
  - Val samples: 272
  - Batch size: 64
  - Steps per epoch: 34
  - Early stopping patience: 50
Epoch   1 | Train Loss: 0.8722 | Val Loss: 1.5723 | Val R²: -0.5966 *
Epoch   3 | Train Loss: 0.6867 | Val Loss: 1.0221 | Val R²: -0.0423 *
Epoch   4 | Train Loss: 0.6627 | Val Loss: 0.5652 | Val R²: 0.4143 *
Epoch   5 | Train Loss: 0.6060 | Val Loss: 0.5374 | Val R²: 0.4418 *
Epoch   6 | Train Loss: 0.5537 | Val Loss: 0.5055 | Val R²: 0.4767 *
Epoch   7 | Train Loss: 0.5337 | Val Loss: 0.4587 | Val R²: 0.5250 *
Epoch   8 | Train Loss: 0.4801 | Val Loss: 0.4172 | Val R²: 0.5671 *
Epoch  11 | Train Loss: 0.3926 | Val Loss: 0.4736 | Val R²: 0.5112
Epoch  13 | Train Loss: 0.3473 | Val Loss: 0.3750 | Val R²: 0.6100 *
Epoch  14 | Train Loss: 0.3270 | Val Loss: 0.3590 | Val R²: 0.6261 *
Epoch  16 | Train Loss: 0.3020 | Val Loss: 0.6399 | Val R²: 0.3414
Epoch  17 | Train Loss: 0.3076 | Val Loss: 0.3450 | Val R²: 0.6409 *
Epoch  21 | Train Loss: 0.3141 | Val Loss: 0.4617 | Val R²: 0.5205
Epoch  26 | Train Loss: 0.2401 | Val Loss: 1.0083 | Val R²: -0.0150
Epoch  27 | Train Loss: 0.2292 | Val Loss: 0.3197 | Val R²: 0.6659 *
Epoch  28 | Train Loss: 0.2152 | Val Loss: 0.3033 | Val R²: 0.6828 *
Epoch  31 | Train Loss: 0.1623 | Val Loss: 0.3712 | Val R²: 0.6141
Epoch  34 | Train Loss: 0.1533 | Val Loss: 0.2978 | Val R²: 0.6888 *
Epoch  36 | Train Loss: 0.1221 | Val Loss: 0.2672 | Val R²: 0.7201 *
Epoch  41 | Train Loss: 0.0918 | Val Loss: 0.2930 | Val R²: 0.6933
Epoch  42 | Train Loss: 0.0805 | Val Loss: 0.2529 | Val R²: 0.7357 *
Epoch  44 | Train Loss: 0.0770 | Val Loss: 0.2421 | Val R²: 0.7474 *
Epoch  46 | Train Loss: 0.0624 | Val Loss: 0.2550 | Val R²: 0.7343
Epoch  48 | Train Loss: 0.0600 | Val Loss: 0.2330 | Val R²: 0.7562 *
Epoch  50 | Train Loss: 0.0573 | Val Loss: 0.2304 | Val R²: 0.7591 *
Epoch  51 | Train Loss: 0.0541 | Val Loss: 0.2305 | Val R²: 0.7587
Epoch  53 | Train Loss: 0.0498 | Val Loss: 0.2276 | Val R²: 0.7618 *
Epoch  54 | Train Loss: 0.0481 | Val Loss: 0.2264 | Val R²: 0.7636 *
Epoch  56 | Train Loss: 0.0475 | Val Loss: 0.2277 | Val R²: 0.7615
Epoch  58 | Train Loss: 0.0465 | Val Loss: 0.2209 | Val R²: 0.7688 *
Epoch  61 | Train Loss: 0.0431 | Val Loss: 0.2244 | Val R²: 0.7659
Epoch  62 | Train Loss: 0.0411 | Val Loss: 0.2197 | Val R²: 0.7703 *
Epoch  65 | Train Loss: 0.0424 | Val Loss: 0.2147 | Val R²: 0.7754 *
Epoch  66 | Train Loss: 0.0401 | Val Loss: 0.2235 | Val R²: 0.7665
Epoch  71 | Train Loss: 0.0360 | Val Loss: 0.2178 | Val R²: 0.7727
Epoch  76 | Train Loss: 0.0349 | Val Loss: 0.2344 | Val R²: 0.7556
Epoch  77 | Train Loss: 0.0326 | Val Loss: 0.2095 | Val R²: 0.7810 *
Epoch  81 | Train Loss: 0.0400 | Val Loss: 0.2365 | Val R²: 0.7528
Epoch  86 | Train Loss: 0.0313 | Val Loss: 0.2229 | Val R²: 0.7671
Epoch  91 | Train Loss: 0.0252 | Val Loss: 0.2075 | Val R²: 0.7827 *
Epoch  96 | Train Loss: 0.0259 | Val Loss: 0.2184 | Val R²: 0.7717
Epoch  97 | Train Loss: 0.0262 | Val Loss: 0.2078 | Val R²: 0.7828 *
Epoch 101 | Train Loss: 0.0224 | Val Loss: 0.2156 | Val R²: 0.7743
Epoch 106 | Train Loss: 0.0251 | Val Loss: 0.2221 | Val R²: 0.7670
Epoch 111 | Train Loss: 0.0250 | Val Loss: 0.2150 | Val R²: 0.7743
Epoch 116 | Train Loss: 0.0219 | Val Loss: 0.2062 | Val R²: 0.7843 *
Epoch 120 | Train Loss: 0.0206 | Val Loss: 0.2040 | Val R²: 0.7864 *
Epoch 121 | Train Loss: 0.0191 | Val Loss: 0.2102 | Val R²: 0.7806
Epoch 126 | Train Loss: 0.0178 | Val Loss: 0.2062 | Val R²: 0.7841
Epoch 128 | Train Loss: 0.0180 | Val Loss: 0.2035 | Val R²: 0.7869 *
Epoch 131 | Train Loss: 0.0176 | Val Loss: 0.2116 | Val R²: 0.7784
Epoch 136 | Train Loss: 0.0172 | Val Loss: 0.2120 | Val R²: 0.7780
Epoch 141 | Train Loss: 0.0161 | Val Loss: 0.2087 | Val R²: 0.7810
Epoch 144 | Train Loss: 0.0159 | Val Loss: 0.2030 | Val R²: 0.7873 *
Epoch 145 | Train Loss: 0.0151 | Val Loss: 0.2015 | Val R²: 0.7884 *
Epoch 146 | Train Loss: 0.0147 | Val Loss: 0.2072 | Val R²: 0.7825
Epoch 147 | Train Loss: 0.0143 | Val Loss: 0.1983 | Val R²: 0.7920 *
Epoch 151 | Train Loss: 0.0145 | Val Loss: 0.2116 | Val R²: 0.7785
Epoch 154 | Train Loss: 0.0131 | Val Loss: 0.1967 | Val R²: 0.7936 *
Epoch 156 | Train Loss: 0.0138 | Val Loss: 0.1999 | Val R²: 0.7905
Epoch 161 | Train Loss: 0.0130 | Val Loss: 0.2114 | Val R²: 0.7788
Epoch 166 | Train Loss: 0.0122 | Val Loss: 0.2011 | Val R²: 0.7896
Epoch 171 | Train Loss: 0.0119 | Val Loss: 0.2070 | Val R²: 0.7834
Epoch 176 | Train Loss: 0.0115 | Val Loss: 0.1971 | Val R²: 0.7931
Epoch 181 | Train Loss: 0.0106 | Val Loss: 0.2076 | Val R²: 0.7829
Epoch 186 | Train Loss: 0.0106 | Val Loss: 0.2016 | Val R²: 0.7890
Epoch 191 | Train Loss: 0.0102 | Val Loss: 0.2069 | Val R²: 0.7837
Epoch 196 | Train Loss: 0.0095 | Val Loss: 0.2008 | Val R²: 0.7898
Epoch 201 | Train Loss: 0.0091 | Val Loss: 0.2050 | Val R²: 0.7852

Early stopping at epoch 204

============================================================
FINAL EVALUATION (Best Model)
============================================================

Overall Val R²: 0.7936
Overall Val Loss: 0.1967

Per-descriptor R²:
  MolWt               : 0.9413
  HeavyAtomCount      : 0.9390
  NumHeteroatoms      : 0.7788
  NumAromaticRings    : 0.8774
  RingCount           : 0.8548
  NOCount             : 0.7617
  NumHDonors          : 0.4500
  NumHAcceptors       : 0.6808
  TPSA                : 0.6698
  MolLogP             : 0.8899
  NumRotatableBonds   : 0.8240
  FractionCSP3        : 0.8556

Hybrid CNN-Transformer training complete!
Best validation R²: 0.7936
Model saved to: models_gpu/hybrid
